{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue' size=5><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "<font color='blue'>Привет! Меня зовут Павел Григорьев, и я буду проверять этот проект.<br>Моя основная цель - не указать на совершённые тобой ошибки, а поделиться своим опытом и помочь тебе совершенствоваться как профессионалу.<br>Спасибо за проделанную работу! Предлагаю общаться на «ты».</font>\n",
    "<details>\n",
    "\t<summary><u>Инструкция по организационным моментам (кликабельно)</u></summary>\n",
    "<font color='blue'>Я буду использовать различные цвета, чтобы было удобнее воспринимать мои комментарии:</font>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<font color='blue'>синий текст - просто текст комментария</font>\n",
    "\n",
    "<font color='green'>✔️ и зеленый текст - все отлично</font>\n",
    "\n",
    "<font color='orange'>⚠️ и оранжевый текст - сделано все правильно, однако есть рекомендации, на что стоит обратить внимание</font>\n",
    "\n",
    "<font color='red'>❌ и красный текст - есть недочеты</font>\n",
    "\n",
    "\n",
    "</details>    \n",
    "    </br>\n",
    "<font color='blue'>Пожалуйста, не удаляй мои комментарии в случае возврата работы, так будет проще разобраться, какие были недочеты, а также сразу увидеть исправленное. </font>\n",
    "\n",
    "Ответы на мои комментарии лучше тоже помечать.\n",
    "Например: <font color='purple'><b>Комментарий студента</b></font>\n",
    "\n",
    "<font color='blue'><b>Давай смотреть, что получилось!</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-Подготовка\" data-toc-modified-id=\"1.-Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>1. Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1.-BERT\" data-toc-modified-id=\"1.1.-BERT-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>1.1. BERT</a></span></li><li><span><a href=\"#1.2.-TF-IDF\" data-toc-modified-id=\"1.2.-TF-IDF-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>1.2. TF-IDF</a></span></li><li><span><a href=\"#1.3.-Изменение-баланса-классов\" data-toc-modified-id=\"1.3.-Изменение-баланса-классов-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>1.3. Изменение баланса классов</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.3.1.-Изменение-весов\" data-toc-modified-id=\"1.3.1.-Изменение-весов-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>1.3.1. Изменение весов</a></span></li><li><span><a href=\"#1.3.2.-Ресемплирование-с-уменьшением-класса-0\" data-toc-modified-id=\"1.3.2.-Ресемплирование-с-уменьшением-класса-0-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>1.3.2. Ресемплирование с уменьшением класса 0</a></span></li></ul></li></ul></li><li><span><a href=\"#2.-Обучение\" data-toc-modified-id=\"2.-Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>2. Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1.-Логистическая-регрессия\" data-toc-modified-id=\"2.1.-Логистическая-регрессия-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>2.1. Логистическая регрессия</a></span></li><li><span><a href=\"#2.2.-LGBM\" data-toc-modified-id=\"2.2.-LGBM-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>2.2. LGBM</a></span></li><li><span><a href=\"#2.3.-CatBoost\" data-toc-modified-id=\"2.3.-CatBoost-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>2.3. CatBoost</a></span></li><li><span><a href=\"#2.4.-LogisticRegression-with-BERT\" data-toc-modified-id=\"2.4.-LogisticRegression-with-BERT-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>2.4. LogisticRegression with BERT</a></span></li></ul></li><li><span><a href=\"#3.-Выводы\" data-toc-modified-id=\"3.-Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>3. Выводы</a></span></li><li><span><a href=\"#4.-Чек-лист-проверки\" data-toc-modified-id=\"4.-Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>4. Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT, запущенным на CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак.\n",
    "\n",
    "**Примечание студента:** поскольку BERT работает долго, а у меня видеокарта RTX 3080, я решила также изучить запуск обучения с использованием её вычислительных ресурсов, используя CUDA-версию библиотеки PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\alner\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\alner\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages (0.15.2+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\alner\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages (2.0.2+cu118)\n",
      "Requirement already satisfied: sympy in c:\\users\\alner\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\alner\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\alner\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\alner\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\alner\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\alner\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages (from torchvision) (2.28.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\alner\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages (from torchvision) (1.20.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\alner\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\alner\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alner\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alner\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alner\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages (from requests->torchvision) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\alner\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\alner\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "# установка CUDA-версии PyTorch\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтоб не забыть, какая библиотека для чего\n",
    "\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# NumPy\n",
    "import numpy as np\n",
    "\n",
    "# графики\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "# для BERT\n",
    "import transformers\n",
    "\n",
    "# чтоб не спамило предупреждениями\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# полоска прогресса\n",
    "from tqdm import notebook\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# разделение выборок, кросс-валидация\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "\n",
    "# метрики (помимо F1 также использовались остальные, на которых построены графики в выводах)\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, precision_score, recall_score, accuracy_score\n",
    "\n",
    "# векторизация текста для TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# логистическая регрессия\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# модель CatBoost\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# LGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "# регулярные выражения\n",
    "import re\n",
    "\n",
    "# лемматизация и стоп-слова (вместо Mystem использую другую библиотеку, т.к. Mystem медленная)\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# перемешивание\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'> Хорошее оформление импортов! \\\n",
    "Импорты собраны в одной ячейке, разделены на функциональные группы пустой строкой.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('toxic_comments.csv')\n",
    "except:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `text` - признак\n",
    "* `toxic` - целевой признак, который нам нужно будет предсказывать (он категориальный, т.е. перед нами задача классификации)\n",
    "\n",
    "В столбце `Unnamed: 0` нет никакой необходимости (он дублирует индекс), поэтому удаляем его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = data.drop('Unnamed: 0', axis=1)\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков в данных нет, но обращает на себя внимание, что все выведенные строчки имеют значение 0 в поле toxic. Проверим и посчитаем все значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'>Данные загружены корректно, первичный осмотр проведен.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data_clean['toxic'].unique())\n",
    "display(data_clean['toxic'].value_counts())\n",
    "data_clean['toxic'].hist(grid=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь виден сильный дисбаланс классов - соотношение 0 и 1 почти 9:1. Для обычных моделей придётся сбалансировать классы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'> Мы обнаружили серьёзный дисбаланс при исследовании данных. Как дополнительные материалы, рекомендую статью <a href='https://dyakonov.org/2021/05/27/imbalance/'>Дисбаланс классов</a>, очень классная, как и весь блог Дьяконова. Ещё такой <a href='https://github.com/Dyakonov/ml_hacks/blob/master/book_disbalance_public_v1.ipynb'>ноутбук</a> есть.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\alner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\alner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\alner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "stopwords = set(nltk_stopwords.words('english')) # поскольку твиты английские, то и стоп-слова из английского\n",
    "tqdm.pandas() # эту конструкцию я подсмотрела, она в дальнейшем позволит без проблем запускать полоску прогресса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь выделяем параметры для BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Expert Categorizers  \\n\\nWhy is there no menti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"\\n\\n Noise \\n\\nfart*  talk. \"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An indefinite block is appropriate, even for a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I don't understand why we have a screenshot of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello! Some of the people, places or things yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Expert Categorizers  \\n\\nWhy is there no menti...      0\n",
       "1                     \"\\n\\n Noise \\n\\nfart*  talk. \"      1\n",
       "2  An indefinite block is appropriate, even for a...      0\n",
       "3  I don't understand why we have a screenshot of...      0\n",
       "4  Hello! Some of the people, places or things yo...      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# константы\n",
    "RANDOM_STATE = 12345 # это также найдёт применение и в обычной модели\n",
    "BERT_SAMPLES = 5000\n",
    "BATCH_SIZE = 500\n",
    "\n",
    "data_bert = data_clean.copy()\n",
    "data_bert = data_clean.sample(BERT_SAMPLES + 500, random_state=RANDOM_STATE).reset_index(drop=True) \n",
    "data_bert.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь проверяем, доступно ли CUDA-устройство."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ⚠️\\\n",
    "<font color='darkorange'> Проверить наличие GPU можно как `torch.cuda.is_available()`.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'><b>Комментарий студента:</b>\n",
    "Поменяла, спасибо. Я изначально так хотела сделать, но не сразу разобралась с установкой PyTorch под CUDA, и остался хвост с экспериментальных попыток.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Устанавливаем видеокарту как устройство, на котором будет работать обучение. Если же устройство недоступно, то PyTorch будет работать на процессоре, как обычно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем предобученную модель и токенизатор, которые и будут подготавливать эмбеддинги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (transformers.BertModel, transformers.BertTokenizer, \n",
    "                                                    'bert-base-uncased')\n",
    "\n",
    "# загрузка предобученной модели/токенизатора \n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)\n",
    "model = model.to(device) # перемещаем работу на видеокарту"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера : </b></font> ✔️\\\n",
    "<font color='green'> Для этой задачи существуют специальные модели, например 'unitary/toxic-bert'</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1408fc603034468c9b7b88f0013b57c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized = data_bert['text'].progress_apply(lambda x: tokenizer.encode(x, add_special_tokens=True, \n",
    "                                                                        truncation=True, max_length=512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ⚠️\\\n",
    "<font color='darkorange'> можно сразу подрезать вектор токенов передав `truncation=True, max_length=512` в Токенизатор.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'><b>Комментарий студента:</b>\n",
    "Готово. Не разобралась, что так можно.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "target = []\n",
    "for i in range(len(tokenized)):\n",
    "    tokens.append(tokenized[i])\n",
    "    target.append(data_bert['toxic'][i])\n",
    "tokens = (pd.Series(tokens)).head(BERT_SAMPLES)\n",
    "target = (pd.Series(target)).head(BERT_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ⚠️\\\n",
    "<font color='darkorange'>Фильтровать можно только обучающие данные. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'><b>Комментарий студента:</b>\n",
    "Не совсем понимаю, что и как тут надо сделать. Сразу разбить на выборки?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa35e4636f204eabb4f09116e6e4534b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3665febf52b4f1eadab239ad87e7151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_len = 0\n",
    "for i in tqdm(tokens.values):\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tqdm(tokens.values)])\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 512)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5000, 512)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(padded.shape, attention_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизация произведена, размеры правильные. Создаём эмбеддинги (само создание происходит на видеокарте, но при создании списка эмбеддингов батчи снова перемещаются в системную память под обработку процессором, т.к. NumPy не поддерживает CUDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ce29d3774e47498f5d3d4960fa761a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = BATCH_SIZE\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.cuda.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.cuda.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().detach().numpy())\n",
    "features_bert = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_bert = target\n",
    "target_bert.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера : </b></font> ✔️\\\n",
    "<font color='green'> 👍</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. TF-IDF\n",
    "\n",
    "Поскольку классы требуют балансировки, нужно провести поиск лучшего способа и сравнить качество. Балансировать можно так:\n",
    "1. Изменение весов в модели обучения\n",
    "2. Ресемплирование с уменьшением класса 0\n",
    "\n",
    "Ресемплирование с увеличением класса 1 не будем использовать из-за громоздкого набора данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS-тегирование\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подсмотрела лемматизатор, который работает быстрее, чем Mystem\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    text = text.lower()\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in word_list])  \n",
    "    text = re.sub(r\"[^a-z']\", ' ', lemmatized_output)\n",
    "    return ' '.join(text.split()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'> Очистка сделана верно! Мы оставили только символы Латинского алфавита.</font> \\\n",
    "<font color='darkorange'> Можно ещё привести символы к одному регистру. Это уменьшит словарь уникальных слов.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'><b>Комментарий студента:</b>\n",
    "У меня под это строчка была на всякий случай, раскомментировала её и поместила в начало функции.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab9d4f4e1a04000950fb39ab130b20f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1h 1min 51s\n",
      "Wall time: 1h 1min 45s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww he match this background colour i 'm see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i 'm really not try to edit war it 's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i ca n't make any real suggestion on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  explanation why the edits make under my userna...  \n",
       "1  d'aww he match this background colour i 'm see...  \n",
       "2  hey man i 'm really not try to edit war it 's ...  \n",
       "3  more i ca n't make any real suggestion on impr...  \n",
       "4  you sir be my hero any chance you remember wha...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_clean['lemm_text'] = data_clean['text'].progress_apply(lemmatize_text)\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'>Здорово что выводишь данные, так удобно отлаживать код, сразу видно, как работает функция.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ❌\\\n",
    "<font color='red'>Обрати внимание, не все слова приведены к начальным формам. Чтобы корректно обработались все части речи, для WordNetLemmatizer() нужно использовать POS-теги (Part of Speech, части речи). Примеры работы с WordNetLemmatizer(), а также с другими инструментами для лемматизации, можно найти в [этой статье](https://webdevblog.ru/podhody-lemmatizacii-s-primerami-v-python/)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'><b>Комментарий студента:</b>\n",
    "Я написала под это ещё одну функцию, вроде бы оно стало работать лучше, но всё ещё не распознаёт краткие формы типа I'm и can't. К тому же время работы очень сильно увеличилось. Есть ли способ это исправить?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьём выборку в соотношении 60:20:20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: (95575, 114770)\n",
      "Размер валидационной выборки: (31858, 114770)\n",
      "Размер тестовой выборки: (31859, 114770)\n"
     ]
    }
   ],
   "source": [
    "target = data_clean['toxic']\n",
    "features = data_clean.drop(['toxic', 'text'], axis=1)\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, \n",
    "                                                                              target, \n",
    "                                                                              test_size=0.4, \n",
    "                                                                              random_state=RANDOM_STATE)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid, \n",
    "                                                                            target_valid, \n",
    "                                                                            test_size=0.5,\n",
    "                                                                            random_state=RANDOM_STATE)\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "features_train = count_tf_idf.fit_transform(features_train['lemm_text'].values)\n",
    "features_valid = count_tf_idf.transform(features_valid['lemm_text'].values)\n",
    "features_test = count_tf_idf.transform(features_test['lemm_text'].values)\n",
    "print('Размер обучающей выборки:', features_train.shape)\n",
    "print('Размер валидационной выборки:', features_valid.shape)\n",
    "print('Размер тестовой выборки:', features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера : </b></font> ✔️\\\n",
    "<font color='green'> Здорово, что у нас есть три выборки!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'> Убрали частые неинформативные слова!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'> Классно, что векторизатор был обучен только на тренировочной части данных!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ⚠️\\\n",
    "<font color='darkorange'> Можно объединить Векторизатор с моделью через Pipeline. Так можно избежать утечек даже при кроссвалидации моделей.<br> Материалы по Pipeline:<br> [О Пайплайн](https://www.helenkapatsa.ru/paiplain/)<br>\n",
    "\n",
    "[Примеры работы с текстами](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_text_feature_extraction.html)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ❌\\\n",
    "<font color='red'>Приводить тексты к юникоду не имеет смысла, так как после очистки осталась только латинница. Юникод  сильно увеличивает  количество потребляемой памяти.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'><b>Комментарий студента:</b>\n",
    "Убрала приведение типов.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из-за размера выборки уменьшаем количество кросс-валидаций до 3, чтобы обрабатывалось не слишком долго. Проверяем значение F1-метрики на исходной выборке (без балансировки классов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на кросс-валидации: 0.685493747351333\n",
      "CPU times: total: 3.75 s\n",
      "Wall time: 3.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv_counts = 3\n",
    "classificator = LogisticRegression()\n",
    "train_f1 = cross_val_score(classificator, \n",
    "                      features_train, \n",
    "                      target_train, \n",
    "                      cv=cv_counts, \n",
    "                      scoring='f1').mean()\n",
    "print('F1 на кросс-валидации:', train_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'>Здорово что оценка кроссвалидацией.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Изменение баланса классов\n",
    "\n",
    "#### 1.3.1. Изменение весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# встроенный метод для тестирования\n",
    "classificator = LogisticRegression(class_weight='balanced')\n",
    "train_f1_balanced = cross_val_score(classificator, \n",
    "                                    features_train, \n",
    "                                    target_train, \n",
    "                                    cv=cv_counts, \n",
    "                                    scoring='f1').mean()\n",
    "print('F1 на кросс-валидации со сбалансированными классами:', train_f1_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера : </b></font> ✔️\\\n",
    "<font color='green'> 👍</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "class_ratio = data_clean['toxic'].value_counts()[0] / data_clean['toxic'].value_counts()[1]\n",
    "display(class_ratio)\n",
    "\n",
    "dict_classes={0:1, 1:class_ratio}\n",
    "classificator = LogisticRegression(class_weight=dict_classes)\n",
    "train_f1_balanced_dict = cross_val_score(classificator, \n",
    "                                    features_train, \n",
    "                                    target_train, \n",
    "                                    cv=cv_counts, \n",
    "                                    scoring='f1').mean()\n",
    "print('F1 на кросс-валидации со сбалансированными классами:', train_f1_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера : </b></font> ✔️\\\n",
    "<font color='green'> 👍</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оба метода дают идентичный результат. Но нужно проверить и ресемплирование.\n",
    "\n",
    "#### 1.3.2. Ресемплирование с уменьшением класса 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_comments_train = data_clean.iloc[target_train.index]\n",
    "\n",
    "target_train_class_zero = toxic_comments_train[toxic_comments_train['toxic'] == 0]['toxic']\n",
    "target_train_class_one = toxic_comments_train[toxic_comments_train['toxic'] == 1]['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train_class_zero_downsample = target_train_class_zero.sample(target_train_class_one.shape[0],\n",
    "                                                                    random_state=RANDOM_STATE)\n",
    "target_train_downsample = pd.concat([target_train_class_zero_downsample, target_train_class_one])\n",
    "\n",
    "features_train_downsample = data_clean.iloc[target_train_downsample.index]\n",
    "features_train_downsample, target_train_downsample = shuffle(features_train_downsample,\n",
    "                                                             target_train_downsample,\n",
    "                                                             random_state=RANDOM_STATE)\n",
    "features_train_downsample = count_tf_idf.transform(features_train_downsample['lemm_text'].values)\n",
    "del count_tf_idf\n",
    "del stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'>Верно, что балансируются только обучающие данные.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на кросс-валидации с уменьшением класса 0: 0.5985285552002418\n",
      "CPU times: total: 1.77 s\n",
      "Wall time: 1.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "classificator = LogisticRegression()\n",
    "train_f1_downsampled = cross_val_score(classificator,\n",
    "                      features_valid, \n",
    "                      target_valid, \n",
    "                      cv=cv_counts, \n",
    "                      scoring='f1').mean()\n",
    "print('F1 на кросс-валидации с уменьшением класса 0:', train_f1_downsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ⚠️\\\n",
    "<font color='darkorange'>Кроссвалидация на сбалансированных данных даёт не корректную оценку. Лучше проверять на несбалансированной валидационной выборке.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'><b>Комментарий студента:</b>\n",
    "Вот так? Я не очень понимаю, как это должно работать, потому что это другая выборка и даунсемплинг, получается, вообще никак не учитывается в проверке.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train_downsample.hist(grid=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, максимальный прирост F1-меры наблюдается при ресемплировании. Нужно проверить ROC-кривую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,9])\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Константная модель')\n",
    "\n",
    "\n",
    "classificator = LogisticRegression()\n",
    "classificator.fit(features_train, target_train)\n",
    "probabilities_valid = classificator.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(target_valid, probabilities_one_valid)\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "valid_f1 = f1_score(target_valid, classificator.predict(features_valid))\n",
    "plt.plot(fpr, tpr, label='Логистическая регрессия')\n",
    "\n",
    "classificator = LogisticRegression(class_weight=dict_classes)\n",
    "classificator.fit(features_train, target_train)\n",
    "probabilities_valid = classificator.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(target_valid, probabilities_one_valid)\n",
    "auc_roc_balanced = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "valid_f1_balanced = f1_score(target_valid, classificator.predict(features_valid))\n",
    "plt.plot(fpr, tpr, label='LR со сбалансированными классами (словарь классов)')\n",
    "\n",
    "classificator = LogisticRegression(class_weight='balanced')\n",
    "classificator.fit(features_train, target_train)\n",
    "probabilities_valid = classificator.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(target_valid, probabilities_one_valid)\n",
    "auc_roc_balanced = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "valid_f1_balanced = f1_score(target_valid, classificator.predict(features_valid))\n",
    "plt.plot(fpr, tpr, label='LR со сбалансированными классами (метод balanced)')\n",
    "\n",
    "classificator = LogisticRegression()\n",
    "classificator.fit(features_train_downsample,target_train_downsample)\n",
    "probabilities_valid = classificator.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(target_valid, probabilities_one_valid)\n",
    "auc_roc_downsampled = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "valid_f1_downsampled = f1_score(target_valid, classificator.predict(features_valid))\n",
    "plt.plot(fpr, tpr, label='LR с даунсемплингом')\n",
    "\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.title(\"ROC-кривая\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь даунсемплинг не оправдал себя - он показывает результат (ROC-кривую) даже хуже, чем модель без какой-либо балансировки. Балансирование классов через словарь соотношения и встроенный метод balanced показало практически идентичные результаты; в дальнейшем будем использовать первый способ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ⚠️\\\n",
    "<font color='blue'>DownSampling сильно сокращает обучающие данные. Модель недоучилась.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'><b>Комментарий студента:</b>\n",
    "Но ведь их всё равно довольно много, выборка-то огромная. Upsampling здесь бы съела кучу ресурсов, как тогда предполагается такие проблемы решать? Через class_weight?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Обучение\n",
    "\n",
    "### 2.1. Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificator = LogisticRegression()\n",
    "hyperparams = [{'solver':['newton-cg', 'lbfgs', 'liblinear'],\n",
    "                'C':[0.1, 1, 10, 100],\n",
    "                'class_weight':[dict_classes]\n",
    "                }]\n",
    "\n",
    "\n",
    "print('Поиск гиперпараметров для f1_score...')\n",
    "print()\n",
    "clf = GridSearchCV(classificator, hyperparams, scoring='f1',cv=cv_counts)\n",
    "clf.fit(features_train, target_train)\n",
    "print(\"Лучший набор параметров:\")\n",
    "print()\n",
    "LR_best_params = clf.best_params_\n",
    "print(LR_best_params)\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.6f for %r\"% (mean, params))\n",
    "print()\n",
    "\n",
    "cv_f1_LR = max(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера : </b></font> ✔️\\\n",
    "<font color='green'>Подбор гиперпараметров проведён верно.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "classificator = LogisticRegression()\n",
    "classificator.set_params(**LR_best_params)\n",
    "classificator.fit(features_train, target_train)\n",
    "target_predict = classificator.predict(features_valid)\n",
    "valid_f1_LR = f1_score(target_valid, target_predict)\n",
    "print('F1 на кросс-валидации:', cv_f1_LR)\n",
    "print('F1 на валидационной выборке:', valid_f1_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера : </b></font> ✔️\\\n",
    "<font color='green'> 👍</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "clf = lgb.LGBMClassifier(class_weight=dict_classes)\n",
    "clf.fit(features_train, target_train)\n",
    "target_predict = classificator.predict(features_valid)\n",
    "cv_f1_lgb = cross_val_score(clf,\n",
    "                                         features_train, \n",
    "                                         target_train, \n",
    "                                         cv=cv_counts, \n",
    "                                         scoring='f1').mean()\n",
    "valid_f1_lgb = f1_score(target_valid, target_predict)\n",
    "print('F1 на кросс-валидации:', cv_f1_lgb)\n",
    "print('F1 на валидационной выборке:', valid_f1_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера : </b></font> ✔️\\\n",
    "<font color='green'> 👍</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "classificator = CatBoostClassifier(verbose=False, iterations=200, class_weights=dict_classes)\n",
    "classificator.fit(features_train, target_train)\n",
    "target_predict = classificator.predict(features_valid)\n",
    "cv_f1_CBC = cross_val_score(classificator,\n",
    "                                         features_train, \n",
    "                                         target_train, \n",
    "                                         cv=cv_counts, \n",
    "                                         scoring='f1').mean()\n",
    "valid_f1_CBC = f1_score(target_valid, target_predict)\n",
    "print('F1 на кросс-валидации:', cv_f1_CBC)\n",
    "print('F1 на валидационной выборке:', valid_f1_CBC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'>CatBoost может сам векторизовать текст. Для этого указываем в класс модели текстовые данные. `text_features=[\"text_lemm\"]`</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. LogisticRegression with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_bert определена выше\n",
    "target_bert = target_bert.head(len(features_bert))\n",
    "\n",
    "features_train_bert, features_test_bert, target_train_bert, target_test_bert = train_test_split(\n",
    "    features_bert, target_bert, test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "classificator = LogisticRegression(class_weight='balanced') # c этим значение получается лучше, чем со словарём\n",
    "classificator.fit(features_train_bert, target_train_bert)\n",
    "target_predict = classificator.predict(features_test_bert)\n",
    "valid_f1_bert = f1_score(target_test_bert, target_predict)\n",
    "# print('F1 на кросс-валидации:', cv_f1_LR)\n",
    "print('F1 на валидационной выборке:', valid_f1_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера : </b></font> ✔️\\\n",
    "<font color='green'> 👍</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На валидационной выборке лучшие результаты показали логистическая регрессия (без BERT) и LightGBM. Поскольку значение F1-метрики на валидационной выборке у них идентично, на тестовых данных проверим обе и построим графики метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,9])\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Константная модель')\n",
    "\n",
    "classificator = LogisticRegression()\n",
    "classificator.set_params(**LR_best_params)\n",
    "classificator.fit(features_train, target_train)\n",
    "probabilities_test = classificator.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(target_test, probabilities_one_test)\n",
    "predict_test = classificator.predict(features_test)\n",
    "plt.plot(fpr, tpr, label='Логистическая регрессия')\n",
    "\n",
    "roc_lr = roc_auc_score(target_test, probabilities_one_test)\n",
    "f1_lr = f1_score(target_test, predict_test)\n",
    "precision_lr = precision_score(target_test, predict_test)\n",
    "recall_lr = recall_score(target_test, predict_test)\n",
    "acc_lr = accuracy_score(target_test, predict_test)\n",
    "\n",
    "classificator = lgb.LGBMClassifier(class_weight=dict_classes)\n",
    "classificator.fit(features_train, target_train)\n",
    "probabilities_test = classificator.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(target_test, probabilities_one_test)\n",
    "predict_test = classificator.predict(features_test)\n",
    "plt.plot(fpr, tpr, label='LightGBM')\n",
    "\n",
    "roc_lgb = roc_auc_score(target_test, probabilities_one_test)\n",
    "f1_lgb = f1_score(target_test, predict_test)\n",
    "precision_lgb = precision_score(target_test, predict_test)\n",
    "recall_lgb = recall_score(target_test, predict_test)\n",
    "acc_lgb = accuracy_score(target_test, predict_test)\n",
    "\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.title(\"ROC-кривая\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'> Отличная визуализация результата!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lr = [roc_lr, f1_lr, precision_lr, recall_lr, acc_lr]\n",
    "results_lgb = [roc_lgb, f1_lgb, precision_lgb, recall_lgb, acc_lgb]\n",
    "\n",
    "cols = ['ROC AUC', 'F1', 'Precision', 'Recall', 'Accuracy']\n",
    "\n",
    "result = pd.DataFrame(data=[results_lr, results_lgb], index=['LogisticRegression', 'LightGBM'], columns=cols)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'> Здорово, что есть табличка результатов для сравнения.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы загрузили данные, представляющие собой ~160 тыс. комментариев интернет-магазина \"Викишоп\". Нам нужно было обучить модель, позволяющую находить токсичные комментарии.\n",
    "Эта задача решалась двумя способами:\n",
    "* классический TF-IDF\n",
    "* с помощью эмбеддингов, полученных на предобученной модели BERT\n",
    "\n",
    "Мы подготовили признаки для двух подходов, для подхода на основе эмбеддингов использовали 5000 сэмплов, т.к. с этим значением BERT справилась за разумное время, позволяющее без проблем перезапускать её для теста (для оптимизации скорости работы использовалась технология CUDA).\n",
    "\n",
    "Из-за дисбаланса классов выборки использовалось изменение их весов, основанное на подсчитанном соотношении классов 0 и 1.\n",
    "\n",
    "Для подхода TF-IDF лучшей моделью оказалась модель LogisticRegression, со значением F1-меры на валидационной выборке в 0.76, на тестовой - 0.75. Порог задачи в 0.75 преодолён.\n",
    "\n",
    "Для подхода, основанном на эмбеддингах, значение F1-меры на валидационной выборке составило 0.66."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'> Очень приятно видеть вывод в конце проекта!\\\n",
    "Приведены ответы на главные вопросы проекта.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Итоговый комментарий ревьюера</b></font>\\\n",
    "<font color='green'>Хороший проект получился!\n",
    "Большое спасибо за проделанную работу. Видно, что приложено много усилий.\n",
    "</font>\n",
    "\n",
    "<font color='blue'>Что нужно исправить:</font>\n",
    "<ul><font color='red'>Не применяй метод .astype('U') для текстов на латинице.</font></ul>\n",
    "<ul><font color='red'>Поправь Лемматизацию.</font></ul>\n",
    "\n",
    "<font color='blue'>Что можно сделать лучше:</font>\n",
    "<font color='orange'>В работе я оставил несколько советов. Буду рад, если ты учтешь их.</font></ul>\n",
    "\n",
    "<font color='blue'><b>Жду новую версию проекта :)</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
